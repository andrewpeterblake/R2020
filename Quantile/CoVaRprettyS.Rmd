---
title: "CoVaR"
author: "Andrew P Blake"
date: "October 2020"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
# setwd("C:/Users/145607/Desktop/HGraphs")
library(quantreg)
library(tidyverse)
```

# CoVaR

A really obvious application of quantile regression is CoVaR, proposed in Adrian, T & M K Brunnermeier, 2016, **CoVaR**, _American Economic Review_ 106(7), 1705-1741. 

It is a generalization of VaR. Consider this, 'borrowed' from Wikipedia:

_Value at risk (VaR) is a measure of the risk of loss for investments. It estimates how much a set of investments might lose (with a given probability), given normal market conditions, in a set time period such as a day. VaR is typically used by firms and regulators in the financial industry to gauge the amount of assets needed to cover possible losses._

_For a given portfolio, time horizon, and probability $p$, the $p$ VaR can be defined informally as the maximum possible loss during that time after we exclude all worse outcomes whose combined probability is at most $p$._

This means we could use QR to, say, calculate the 5th quantile of some risky asset as a measure of VaR in that kind of 'extreme' event. CoVaR goes further by looking at he systemic effects, to evaluate how important an extreme event for one institution is for another. The maths makes it easy to understand. 

# Equations

Imagine that we forecast a return for institution $i$ using:
$$
  X_t^i = \alpha^i + \gamma^i M_{t-1}^i + \varepsilon_t^i
$$
indexed by institution $i$, 'risky' asset $X$ and some explanatory variables $M$. Then the system value for the same asset is:
$$
  X^{system|i}_t = \alpha^{system|i} + \beta^{system|i} X_t^i + \gamma^{system|i} M_{t-1} + \varepsilon_t^{system|i}
$$

If we use quantile regression, and choose some quantile, here $q=0.05$, i.e. 5\%, we get the definition of $VaR$ for $i$ at some time $t$ given some state variables $M_t$. So:
$$
  VaR_t^i(q) = \hat{\alpha}_q^i + \hat{\gamma}^i_q M^i_{t-1}
$$
and the $CoVaR$ measure uses this in the system equations so:
$$
  CoVaR_t^i(q) = \hat{\alpha}_q^{system|i} + \hat{\beta}^{system|i}_q VaR^i_t(q) + \hat{\gamma}^{system|i}_q M_{t-1}
$$
with $\Delta CoVaR$ defined as:
$$
  \Delta CoVaR_q^{system|VaR^i_q} = \hat{\beta}^{system|i}_q \left(VaR^i_t(q) - VaR^i_t(50\%)\right )
$$
So we need to run three quantile regressions per $i$ for every sample to calculate both $CoVaR$ and $\Delta CoVaR$.

# Data

WE will look at three big UK bankls and assume they form a system. Data is obtained from Yahoo, for example [Barclays](https://uk.finance.yahoo.com/quote/BARC.L/history/).

The data comprises the returns for the three individual banks:
```{r pressure, echo=TRUE, message=FALSE}
HSBC     <- read_csv("Yahoo/HSBA.L.csv", na="null") %>% 
  select(Date, HSBC = Close)
LLOY     <- read_csv("Yahoo/LLOY.L.csv") %>% 
  select(Date, Lloyds = Close)
BARC     <- read_csv("Yahoo/BARC.L.csv") %>% 
  select(Date, Barclays = Close)

Data0    <- full_join(BARC, HSBC) %>% 
  full_join(LLOY) %>%
  pivot_longer(cols=-Date, names_to = "Vars", values_to = "Vals") %>%
  group_by(Vars) %>%
  mutate(Vals = (Vals/lag(Vals, 1) - 1)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = Vars, values_from = Vals)

Data0 %>% pivot_longer(cols=-Date, names_to="Vars", values_to = "Vals") %>% 
  ggplot() +
  geom_line(aes(x=Date, y=Vals, group=Vars, color=Vars)) +
  theme_minimal() + 
  facet_wrap(~Vars, scales = "free_y") +
  theme(legend.position = "none") +
  labs(title="Institution returns", x="", y="")
```

and some state variables which we will pick to be the VIX and the FTSE100 return^[There seems to be a limit on downloading longer spans of index data but oddly not share price data. To get round this I've used overlapping chunks of data and then joined them all up.]
```{r echo=TRUE, warning=FALSE, message=FALSE}

X_FTSE_1 <- read_csv("Yahoo/^FTSE_1.csv")
X_FTSE_2 <- read_csv("Yahoo/^FTSE_2.csv")
X_FTSE_3 <- read_csv("Yahoo/^FTSE_3.csv")
X_FTSE_4 <- read_csv("Yahoo/^FTSE_4.csv")
FTSE     <- full_join(X_FTSE_1, X_FTSE_2) %>% 
  full_join(X_FTSE_3) %>%
  full_join(X_FTSE_4) %>% 
  select(Date, FTSE = Close)
VIX      <- read_csv("Yahoo/^VIX.csv") %>% 
  select(Date, VIX = Close)

State    <-  full_join(FTSE, VIX, by="Date") %>%
  mutate(FTSE.return = 100*(log(FTSE) - lag(log(FTSE)))) %>%
  select(-FTSE) %>% 
  mutate(Date = lead(Date)) # Artificially create the data as lags

gather(State, Var, Val, -Date) %>% 
  ggplot() +
  geom_line(aes(x=Date, y=Val, group=Var, color=Var)) +
  theme_minimal() + 
  facet_wrap(~Var, scales="free_y") +
  theme(legend.position="none") +
  labs(title="Lagged states", x="", y="")
```

We join the data together:
```{r}
Data <- Data0 %>% 
  inner_join(State, by="Date") %>%
  drop_na()
```

# Full sample estimates

To estimate the equations and calculate $CoVaR$ is pretty easy for the full sample:
```{r}
state_names <- names(State)[-1]
maxs        <- nrow(Data)

Results <- list()
for (j in 1:3)  { # Each institution
  
  wbank <- colnames(Data)[j+1] 
  Data2 <- Data %>%
    mutate(System.returns = rowMeans(select(., -Date, -all_of(wbank), -all_of(state_names)))) # Average return excluding Institution i
  eqn.inst <- formula(paste0(wbank, " ~ ", paste(state_names, collapse="+")))
  eqn.syst <- formula(paste0("System.returns ~ ", wbank, " + ", paste(state_names, collapse="+")))

  # Fit QR at 0.05 - VaR institution
  VaR.inst <- rq(eqn.inst, data=Data2, tau=0.05, ci=TRUE)
  print(summary(VaR.inst))
  
  # Fit QR at 0.05 - VaR system
  VaR.syst <- rq(eqn.syst, data=Data2, tau=0.05, ci=TRUE)
  print(summary(VaR.syst))
  
  # CoVaR
  fit.inst <- fitted(VaR.inst)     # VaR in every period
  bb       <- coef(VaR.syst)[,1]   # System parameters
  RHS      <- data.matrix(select(Data2, all_of(state_names)))  # Rest of predictors
  CoVaR    <- bb[1] + bb[2]*fit.inst + RHS %*% bb[-(1:2)]

  # Results
  Results[[j]] <- Data2 %>%
    mutate(VaR.institution = as.numeric(fit.inst), 
           VaR.system      = as.numeric(fitted(VaR.syst)), 
           CoVaR           = as.numeric(CoVaR),
           Bank            = wbank)
}
```

Obvious issue that many of the coefficient estimate bounds straddle zero. However, estimated CoVaR is:
```{r}
Results %>%
  bind_rows() %>%
  select(Date, CoVaR, Bank) %>%
  gather(Measure, Val, -Date, -Bank) %>% 
  ggplot() +
  geom_line(aes(x=Date, y=Val, group=Measure, color=Bank)) +
  theme_minimal() +
  facet_wrap(~ Bank) +
  labs(title="CoVaR", x="", y="")
```

## Recursive estimates

In practice we would do real time estimation, and we can simulate that by using recursive estimates because we have no data that would be revised. Recursive estimation allows us to see how the coefficient estimates evolve through time as well as the CoVaR estimates themselves. 

```{r}
EstCoefI <- list()
EstCoefS <- list()
p        <- 0
for (j in 1:3)  { # Each institution
  
  wbank <- colnames(Data)[j+1] 
  Data1 <- Data %>%
    mutate(System.returns = rowMeans(select(., -all_of(wbank), -Date, -all_of(state_names))))
  
  eqn.inst <- formula(paste0(wbank, " ~ ", paste(state_names, collapse="+")))
  eqn.syst <- formula(paste0("System.returns ~ ", wbank, " + ",
                             paste(state_names, collapse="+")))
  
  for (j in seq(130, maxs, 1)) {

    Data2    <- head(Data1, j) # Simple way to control sample
    # Fit QR at 0.05 - VaR institution
    VaR.inst <- rq(eqn.inst, data=Data2, tau=0.05, ci=TRUE)
    # Fit QR at 0.05 - VaR system
    VaR.syst <- rq(eqn.syst, data=Data2, tau=0.05, ci=TRUE)
    # Results
    p <- p+1
    EstCoefI[[p]] <- data.frame(Coef   = rownames(VaR.inst$coefficients), 
                                VaR.inst$coefficients, 
                                Sample = max(Data2$Date),
                                Bank   = wbank, stringsAsFactors = FALSE)
    EstCoefS[[p]] <- data.frame(Coef   = rownames(VaR.syst$coefficients), 
                                VaR.syst$coefficients, 
                                Sample = max(Data2$Date),
                                Bank   = wbank, stringsAsFactors = FALSE)
  }
}
```

Plot these: 

```{r fig.height=8}
ff      <- names(Data)
ff[1]   <- "(Intercept)"

EstCoefI %>%
  bind_rows() %>%
  mutate(Coef = factor(Coef, levels=ff), Sample = as.Date(Sample)) %>%
  ggplot() + 
  geom_line(aes(x=Sample, y=coefficients, color=Bank))  + 
  geom_line(aes(x=Sample, y=lower.bd), color= "grey55", linetype=2)  + 
  geom_line(aes(x=Sample, y=upper.bd), color= "grey55", linetype=2)  + 
  facet_grid(Coef~Bank, scales = "free") +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Recursive coefficient estimates: Individual", x="", y="")

```

and

```{r fig.height=10}
EstCoefS %>%
  bind_rows() %>%
  mutate(Coef = factor(Coef, levels = ff), Sample = as.Date(Sample)) %>%
  ggplot() + 
  geom_line(aes(x=Sample, y=coefficients, color=Bank))  + 
  geom_line(aes(x=Sample, y=lower.bd), color= "grey55", linetype=2)  + 
  geom_line(aes(x=Sample, y=upper.bd), color= "grey55", linetype=2)  + 
  facet_grid(Coef~Bank, scales = "free") +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Recursive coefficient estimates: System", x="", y="")
```


## Calculating $\Delta CoVaR$ and a look at uncertainty

Do recursive estimates and recursive value calculations.
```{r warning=FALSE}
AllData  <- list()
EstCoefI <- list()
EstCoefS <- list()
p        <- 0
for (j in 1:3)  { # Each institution
  
  wbank <- colnames(Data)[j+1] 
  Data1 <- Data %>%
    mutate(System.returns = rowMeans(select(., -c(all_of(wbank), Date, all_of(state_names))))) 

  eqn.inst <- formula(paste0(wbank," ~ ",paste(state_names,collapse=" + ")))
  eqn.syst <- formula(paste0("System.returns ~ ",wbank," + ",paste(state_names,collapse=" + ")))

  for (k in seq(132, maxs, 1)) {

    # Set sample
    Data2 <- head(Data1, k)
    
    # Fit QR at 0.05 - VaR institution
    VaR.inst <- rq(eqn.inst, data=Data2, tau=0.05, ci=TRUE)
    M.inst   <- rq(eqn.inst, data=Data2, tau=0.5, ci=TRUE)
    
    fit.inst <- fitted(VaR.inst)
    fit.M    <- fitted(M.inst)

    # Fit QR at 0.05 - VaR system
    VaR.syst <- rq(eqn.syst, data=Data2, tau=0.05, ci=TRUE)

    # CoVaR
    RHS    <- data.matrix(select(Data2, all_of(state_names)))
    bb     <- coef(VaR.syst)[,1]
    bbm    <- coef(VaR.syst)[2,1] # estimate
    bbl    <- coef(VaR.syst)[2,2] # lower bound 
    bbu    <- coef(VaR.syst)[2,3] # upper bound
    CoVaR  <- bb[1] + bb[2]*fit.inst + RHS %*% bb[-(1:2)]
    DCoVaRm <- bbm*(fit.inst - fit.M) # DCoVaR at etimate
    DCoVaRl <- bbl*(fit.inst - fit.M) # at lower bound
    DCoVaRu <- bbu*(fit.inst - fit.M) # at upper bound

    # Results
    p <- p+1
    AllData[[p]] <- Data2 %>%
      mutate(VaR.institution = as.numeric(fit.inst), 
             VaR.system      = as.numeric(fitted(VaR.syst)), 
             CoVaR           = as.numeric(CoVaR),
             DCoVaRm         = as.numeric(DCoVaRm),
             DCoVaRl         = as.numeric(DCoVaRl),
             DCoVaRu         = as.numeric(DCoVaRu),
             Bank            = wbank,
             Sample          = max(Date))
    
    EstCoefI[[p]] <- data.frame(Coef   = rownames(VaR.inst$coefficients), 
                                VaR.inst$coefficients, 
                                Sample = max(Data2$Date),
                                Bank   = wbank, 
                                stringsAsFactors = FALSE)
    EstCoefS[[p]] <- data.frame(Coef   = rownames(VaR.syst$coefficients), 
                                VaR.syst$coefficients, 
                                Sample = max(Data2$Date),
                                Bank   = wbank, 
                                stringsAsFactors = FALSE)
  }
}
```

Calculate variables that are the maximum/minimum by Date/Institution. This allows us to plot swathes.

```{r}
AllData <- AllData %>% 
  bind_rows() %>%
  group_by(Date, Bank) %>%
  mutate(MaxC  = max(CoVaR),   MinC  = min(CoVaR)) %>%
  mutate(MaxDm = max(DCoVaRm), MinDm = min(DCoVaRm)) %>%
  mutate(MaxDl = max(DCoVaRl), MinDl = min(DCoVaRl)) %>%
  mutate(MaxDu = max(DCoVaRu), MinDu = min(DCoVaRu)) %>%
  ungroup()

AllData %>%
  select(Date, MaxC, MinC, CoVaR, Sample, Bank) %>%
  distinct() %>% 
  ggplot() +
  geom_ribbon(data= . %>% filter(Sample == max(Sample)),
    aes(x=Date, ymin=MinC, ymax=MaxC, group=Bank, fill=Bank, color=Bank)) +
  geom_line(data= . %>% filter(Sample == Date),
            aes(x=Date, y=CoVaR, group=Bank), size=0.75, color="grey11") +
  theme_minimal() +
  facet_wrap(~Bank) +
  labs(title="Spread of CoVaR estimates", x="", y="",
       subtitle="Shaded swathes of min-max recursive estimates, black real-time estimate") +
  theme(legend.position = "none")

AllData %>%
  select(Date, MaxC, MinC, CoVaR, Sample, Bank) %>%
  distinct() %>% 
  ggplot() +
  geom_ribbon(data= . %>% filter(Sample == max(Sample)),
    aes(x=Date, ymin=MinC, ymax=MaxC, group=Bank, fill=Bank, color=Bank)) +
  geom_line(data= . %>% filter(Sample == max(Date)),
            aes(x=Date, y=CoVaR, group=Bank), size=0.75, color="grey11") +
  theme_minimal() +
  facet_wrap(~Bank) +
  labs(title="Spread of CoVaR estimates", x="", y="",
       subtitle="Shaded swathes of min-max recursive estimates, black final sample estimate") +
  theme(legend.position = "none")

AllData %>%
  select(Date, MaxDl, MinDl, MaxDm, MinDm, MaxDu, MinDu, Bank) %>%
  distinct() %>% 
  ggplot() +
  geom_ribbon(aes(x=Date, ymin=MinDl, ymax=MaxDl), fill="red", color=NA, alpha = .4) +
  geom_ribbon(aes(x=Date, ymin=MinDu, ymax=MaxDu), fill="green", color=NA, alpha = .4) +
  theme_minimal() +
  facet_wrap(~Bank) +
  labs(title="Spread of DCoVaR estimates", x="", y="") +
  theme(legend.position = "none")
```


